"""
å·¥å…·å‡½æ•¸æ¨¡çµ„ - æä¾›ç·©å­˜ç®¡ç†å’Œç³»çµ±è¨ºæ–·åŠŸèƒ½
"""
print("[utils] âœ… å·²è¼‰å…¥å·¥å…·æ¨¡çµ„")

import os
import glob
import json
import time
import random
import datetime
import requests
import shutil
import sys
import importlib

# è¨­å®šç·©å­˜ç›®éŒ„ä½ç½®
CACHE_DIR = os.path.join(os.path.dirname(__file__), '../cache')
os.makedirs(CACHE_DIR, exist_ok=True)

def clear_cache(file_pattern="*.json", days_old=None):
    """
    æ¸…ç†ç·©å­˜æ–‡ä»¶
    
    åƒæ•¸:
    - file_pattern: è¦åˆªé™¤çš„æ–‡ä»¶æ¨¡å¼ (ä¾‹å¦‚ "*.json")
    - days_old: åªåˆªé™¤æŒ‡å®šå¤©æ•¸ä»¥ä¸Šçš„æ–‡ä»¶ï¼ŒNone è¡¨ç¤ºåˆªé™¤æ‰€æœ‰ç¬¦åˆæ¨¡å¼çš„æ–‡ä»¶
    
    è¿”å›:
    - (int, int): æˆåŠŸåˆªé™¤çš„æ–‡ä»¶æ•¸é‡ï¼Œå¤±æ•—çš„æ–‡ä»¶æ•¸é‡
    """
    success = 0
    failure = 0

    # ç¢ºä¿ç·©å­˜ç›®éŒ„å­˜åœ¨
    if not os.path.exists(CACHE_DIR):
        print(f"[utils] âš ï¸ ç·©å­˜ç›®éŒ„ä¸å­˜åœ¨: {CACHE_DIR}")
        return success, failure

    # å–å¾—ç¬¦åˆæ¨¡å¼çš„æ‰€æœ‰ç·©å­˜æ–‡ä»¶
    cache_files = glob.glob(os.path.join(CACHE_DIR, file_pattern))
    
    if not cache_files:
        print(f"[utils] â„¹ï¸ æ‰¾ä¸åˆ°ç¬¦åˆæ¨¡å¼çš„ç·©å­˜æ–‡ä»¶: {file_pattern}")
        return success, failure
    
    now = datetime.datetime.now()
    
    for cache_file in cache_files:
        try:
            # æª¢æŸ¥æ–‡ä»¶ä¿®æ”¹æ™‚é–“
            if days_old is not None:
                file_modified = datetime.datetime.fromtimestamp(os.path.getmtime(cache_file))
                days_diff = (now - file_modified).days
                
                if days_diff < days_old:
                    continue  # è·³éä¸å¤ èˆŠçš„æ–‡ä»¶
            
            # åˆªé™¤æ–‡ä»¶
            os.remove(cache_file)
            print(f"[utils] âœ… å·²åˆªé™¤ç·©å­˜æª”æ¡ˆ: {os.path.basename(cache_file)}")
            success += 1
            
        except Exception as e:
            print(f"[utils] âš ï¸ ç„¡æ³•åˆªé™¤ç·©å­˜æª”æ¡ˆ {os.path.basename(cache_file)}: {e}")
            failure += 1
    
    print(f"[utils] ç·©å­˜æ¸…ç†å®Œæˆ: {success} å€‹æ–‡ä»¶å·²åˆªé™¤ï¼Œ{failure} å€‹æ–‡ä»¶åˆªé™¤å¤±æ•—")
    return success, failure

def check_network_connectivity(targets=None, timeout=5):
    """
    æª¢æŸ¥ç¶²è·¯é€£ç·šç‹€æ…‹
    
    åƒæ•¸:
    - targets: è¦æª¢æŸ¥çš„ç¶²ç«™åˆ—è¡¨ï¼ŒNone å‰‡ä½¿ç”¨é è¨­åˆ—è¡¨
    - timeout: é€£ç·šé€¾æ™‚æ™‚é–“ (ç§’)
    
    è¿”å›:
    - dict: é€£ç·šçµæœå­—å…¸
    """
    if targets is None:
        targets = [
            "https://www.twse.com.tw",          # å°ç£è­‰åˆ¸äº¤æ˜“æ‰€
            "https://mops.twse.com.tw",          # å…¬é–‹è³‡è¨Šè§€æ¸¬ç«™
            "https://isin.twse.com.tw",          # è­‰åˆ¸ä»£è™ŸæŸ¥è©¢ç³»çµ±
            "https://finance.yahoo.com",         # Yahoo Finance
            "https://www.google.com"             # Google (é€£ç·šæ¸¬è©¦åŸºæº–)
        ]
    
    results = {}
    
    print("[utils] ğŸ“¡ ç¶²è·¯é€£ç·šè¨ºæ–·:")
    for url in targets:
        try:
            start_time = time.time()
            response = requests.get(url, timeout=timeout)
            latency = time.time() - start_time
            
            results[url] = {
                "status": response.status_code,
                "latency": round(latency, 2),
                "success": response.status_code == 200
            }
            
            status = "âœ…" if results[url]["success"] else "âŒ"
            print(f"  {status} {url}: {response.status_code} (å»¶é²: {results[url]['latency']}ç§’)")
            
        except Exception as e:
            results[url] = {
                "status": "error",
                "latency": None,
                "success": False,
                "error": str(e)
            }
            print(f"  âŒ {url}: é€£ç·šå¤±æ•— ({str(e)})")
    
    # è¨ˆç®—é€£ç·šæˆåŠŸç‡
    success_count = sum(1 for r in results.values() if r["success"])
    success_rate = (success_count / len(targets)) * 100
    
    print(f"[utils] ç¶²è·¯é€£ç·šæˆåŠŸç‡: {success_rate:.1f}% ({success_count}/{len(targets)})")
    
    # è¿”å›é€£ç·šç‹€æ…‹å’Œæ˜¯å¦å…¨éƒ¨æˆåŠŸ
    return {
        "results": results,
        "success_rate": success_rate,
        "all_success": all(r["success"] for r in results.values())
    }

def create_cache_file(key, data, expiry_hours=24):
    """
    å‰µå»ºç·©å­˜æ–‡ä»¶
    
    åƒæ•¸:
    - key: ç·©å­˜éµå
    - data: è¦å„²å­˜çš„æ•¸æ“š
    - expiry_hours: éæœŸæ™‚é–“ (å°æ™‚)
    
    è¿”å›:
    - bool: æ˜¯å¦æˆåŠŸå‰µå»º
    """
    try:
        cache_file = os.path.join(CACHE_DIR, f"{key}.json")
        
        cache_data = {
            "timestamp": datetime.datetime.now().isoformat(),
            "expiry": (datetime.datetime.now() + datetime.timedelta(hours=expiry_hours)).isoformat(),
            "data": data
        }
        
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
        print(f"[utils] âœ… å·²å‰µå»ºç·©å­˜æ–‡ä»¶: {key}.json")
        return True
        
    except Exception as e:
        print(f"[utils] âŒ å‰µå»ºç·©å­˜æ–‡ä»¶å¤±æ•— ({key}): {e}")
        return False

def get_cache_file(key, default=None):
    """
    è®€å–ç·©å­˜æ–‡ä»¶
    
    åƒæ•¸:
    - key: ç·©å­˜éµå
    - default: ç•¶ç·©å­˜ä¸å­˜åœ¨æˆ–å·²éæœŸæ™‚è¿”å›çš„é»˜èªå€¼
    
    è¿”å›:
    - ç·©å­˜çš„æ•¸æ“šï¼Œæˆ–è€…é»˜èªå€¼
    """
    try:
        cache_file = os.path.join(CACHE_DIR, f"{key}.json")
        
        if not os.path.exists(cache_file):
            return default
            
        with open(cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)
            
        # æª¢æŸ¥éæœŸæ™‚é–“
        if "expiry" in cache_data:
            expiry_time = datetime.datetime.fromisoformat(cache_data["expiry"])
            
            if datetime.datetime.now() > expiry_time:
                print(f"[utils] âš ï¸ ç·©å­˜å·²éæœŸ: {key}.json")
                return default
                
        print(f"[utils] âœ… ä½¿ç”¨ç·©å­˜: {key}.json")
        return cache_data.get("data", default)
        
    except Exception as e:
        print(f"[utils] âŒ è®€å–ç·©å­˜æ–‡ä»¶å¤±æ•— ({key}): {e}")
        return default

def check_module_dependencies():
    """
    æª¢æŸ¥æ‰€éœ€æ¨¡çµ„æ˜¯å¦å·²å®‰è£
    
    è¿”å›:
    - dict: æ¨¡çµ„æª¢æŸ¥çµæœ
    """
    required_modules = [
        "pandas",
        "numpy",
        "requests",
        "bs4",
        "yfinance",
        "tqdm"
    ]
    
    results = {}
    print("[utils] æª¢æŸ¥æ¨¡çµ„ä¾è³´...")
    
    for module_name in required_modules:
        try:
            module = importlib.import_module(module_name)
            version = getattr(module, "__version__", "æœªçŸ¥")
            results[module_name] = {
                "installed": True,
                "version": version
            }
            print(f"  âœ… {module_name}: v{version}")
        except ImportError:
            results[module_name] = {
                "installed": False,
                "version": None
            }
            print(f"  âŒ {module_name}: æœªå®‰è£")
    
    # æª¢æŸ¥æ‰€æœ‰æ¨¡çµ„æ˜¯å¦éƒ½å·²å®‰è£
    all_installed = all(r["installed"] for r in results.values())
    
    if all_installed:
        print("[utils] âœ… æ‰€æœ‰å¿…è¦æ¨¡çµ„å·²å®‰è£")
    else:
        missing = [name for name, result in results.items() if not result["installed"]]
        print(f"[utils] âš ï¸ ç¼ºå°‘ä»¥ä¸‹æ¨¡çµ„: {', '.join(missing)}")
        print("[utils] è«‹ä½¿ç”¨ pip install -r requirements.txt å®‰è£ç¼ºå°‘çš„æ¨¡çµ„")
    
    return {
        "results": results,
        "all_installed": all_installed
    }

def check_system_health():
    """
    å…¨é¢æª¢æŸ¥ç³»çµ±å¥åº·ç‹€æ…‹ (ç¶²è·¯ã€æ¨¡çµ„ã€ç·©å­˜ç›®éŒ„)
    
    è¿”å›:
    - dict: ç³»çµ±å¥åº·ç‹€æ…‹
    """
    print(f"[utils] ğŸ” é–‹å§‹æª¢æŸ¥ç³»çµ±å¥åº·ç‹€æ…‹...")
    
    # æª¢æŸ¥ Python ç‰ˆæœ¬
    python_version = sys.version
    print(f"[utils] Python ç‰ˆæœ¬: {python_version}")
    
    # æª¢æŸ¥æ¨¡çµ„ä¾è³´
    module_check = check_module_dependencies()
    
    # æª¢æŸ¥ç¶²è·¯é€£æ¥
    network_check = check_network_connectivity()
    
    # æª¢æŸ¥ç·©å­˜ç›®éŒ„
    cache_status = {"exists": False, "writeable": False, "size": 0, "files": 0}
    
    if os.path.exists(CACHE_DIR):
        cache_status["exists"] = True
        
        # æª¢æŸ¥ç›®éŒ„æ˜¯å¦å¯å¯«
        test_file = os.path.join(CACHE_DIR, f"test_{random.randint(1000, 9999)}.tmp")
        try:
            with open(test_file, 'w') as f:
                f.write("test")
            os.remove(test_file)
            cache_status["writeable"] = True
        except:
            cache_status["writeable"] = False
        
        # è¨ˆç®—ç·©å­˜å¤§å°å’Œæ–‡ä»¶æ•¸é‡
        try:
            cache_files = os.listdir(CACHE_DIR)
            cache_status["files"] = len(cache_files)
            
            total_size = 0
            for file_name in cache_files:
                file_path = os.path.join(CACHE_DIR, file_name)
                if os.path.isfile(file_path):
                    total_size += os.path.getsize(file_path)
            
            cache_status["size"] = total_size
            cache_size_mb = total_size / (1024 * 1024)
            
            print(f"[utils] ç·©å­˜ç‹€æ…‹: {cache_status['files']} å€‹æ–‡ä»¶, {cache_size_mb:.2f} MB")
        except Exception as e:
            print(f"[utils] âš ï¸ ç„¡æ³•è¨ˆç®—ç·©å­˜å¤§å°: {e}")
    else:
        print(f"[utils] âš ï¸ ç·©å­˜ç›®éŒ„ä¸å­˜åœ¨: {CACHE_DIR}")
    
    # æ•´é«”ç³»çµ±å¥åº·è©•ä¼°
    system_healthy = (
        module_check["all_installed"] and
        network_check["success_rate"] >= 60 and  # è‡³å°‘æœ‰ 60% çš„ç¶²ç«™å¯ä»¥é€£æ¥
        cache_status["exists"] and
        cache_status["writeable"]
    )
    
    health_status = "âœ… å¥åº·" if system_healthy else "âš ï¸ æœ‰å•é¡Œ"
    print(f"[utils] ç³»çµ±å¥åº·ç‹€æ…‹: {health_status}")
    
    return {
        "status": system_healthy,
        "python_version": python_version,
        "modules": module_check,
        "network": network_check,
        "cache": cache_status,
        "timestamp": datetime.datetime.now().isoformat()
    }

def backup_cache():
    """
    å‚™ä»½ç·©å­˜ç›®éŒ„
    
    è¿”å›:
    - str: å‚™ä»½æ–‡ä»¶è·¯å¾‘ï¼Œæˆ–è€… None è¡¨ç¤ºå¤±æ•—
    """
    if not os.path.exists(CACHE_DIR) or not os.listdir(CACHE_DIR):
        print("[utils] âš ï¸ ç·©å­˜ç›®éŒ„ä¸å­˜åœ¨æˆ–ç‚ºç©ºï¼Œç„¡éœ€å‚™ä»½")
        return None
    
    try:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = f"cache_backup_{timestamp}.zip"
        backup_path = os.path.join(os.path.dirname(CACHE_DIR), backup_file)
        
        # å‰µå»º ZIP å‚™ä»½
        shutil.make_archive(
            os.path.splitext(backup_path)[0],  # ä¸åŒ…å«æ“´å±•åçš„è·¯å¾‘
            'zip',                             # å£“ç¸®æ ¼å¼
            CACHE_DIR                         # è¦å£“ç¸®çš„ç›®éŒ„
        )
        
        print(f"[utils] âœ… å·²å‰µå»ºç·©å­˜å‚™ä»½: {backup_file}")
        return backup_path
        
    except Exception as e:
        print(f"[utils] âŒ å‰µå»ºç·©å­˜å‚™ä»½å¤±æ•—: {e}")
        return None

def restore_cache_backup(backup_path):
    """
    å¾å‚™ä»½æª”æ¡ˆæ¢å¾©ç·©å­˜
    
    åƒæ•¸:
    - backup_path: å‚™ä»½æ–‡ä»¶è·¯å¾‘
    
    è¿”å›:
    - bool: æ˜¯å¦æˆåŠŸæ¢å¾©
    """
    if not os.path.exists(backup_path):
        print(f"[utils] âŒ å‚™ä»½æª”æ¡ˆä¸å­˜åœ¨: {backup_path}")
        return False
    
    try:
        # é‡å»ºç·©å­˜ç›®éŒ„
        if os.path.exists(CACHE_DIR):
            shutil.rmtree(CACHE_DIR)
        os.makedirs(CACHE_DIR)
        
        # è§£å£“ç¸®å‚™ä»½æª”æ¡ˆ
        shutil.unpack_archive(backup_path, CACHE_DIR)
        
        print(f"[utils] âœ… å·²å¾å‚™ä»½æ¢å¾©ç·©å­˜: {os.path.basename(backup_path)}")
        return True
        
    except Exception as e:
        print(f"[utils] âŒ æ¢å¾©ç·©å­˜å¤±æ•—: {e}")
        return False

def log_system_status():
    """
    è¨˜éŒ„ç³»çµ±ç‹€æ…‹åˆ°æ—¥èªŒæª”æ¡ˆ
    
    è¿”å›:
    - str: æ—¥èªŒæª”æ¡ˆè·¯å¾‘
    """
    try:
        log_dir = os.path.join(os.path.dirname(__file__), '../logs')
        os.makedirs(log_dir, exist_ok=True)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(log_dir, f"system_status_{timestamp}.json")
        
        # ç²å–ç³»çµ±å¥åº·ç‹€æ…‹
        status = check_system_health()
        
        # å¯«å…¥æ—¥èªŒæª”æ¡ˆ
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(status, f, ensure_ascii=False, indent=2)
            
        print(f"[utils] âœ… å·²è¨˜éŒ„ç³»çµ±ç‹€æ…‹: {os.path.basename(log_file)}")
        return log_file
        
    except Exception as e:
        print(f"[utils] âŒ è¨˜éŒ„ç³»çµ±ç‹€æ…‹å¤±æ•—: {e}")
        return None

# ç•¶æ¨¡çµ„è¢«ç›´æ¥åŸ·è¡Œæ™‚
if __name__ == "__main__":
    print("å°è‚¡åˆ†æç³»çµ±å·¥å…·æ¨¡çµ„")
    print("=" * 50)
    
    # åŸºæ–¼å‘½ä»¤åˆ—åƒæ•¸åŸ·è¡ŒåŠŸèƒ½
    import argparse
    
    parser = argparse.ArgumentParser(description='ç³»çµ±å·¥å…·å‘½ä»¤')
    parser.add_argument('--check', action='store_true', help='æª¢æŸ¥ç³»çµ±å¥åº·ç‹€æ…‹')
    parser.add_argument('--clear-cache', action='store_true', help='æ¸…ç†ç·©å­˜')
    parser.add_argument('--backup', action='store_true', help='å‚™ä»½ç·©å­˜')
    parser.add_argument('--restore', type=str, help='å¾æŒ‡å®šå‚™ä»½æª”æ¡ˆæ¢å¾©ç·©å­˜')
    parser.add_argument('--network', action='store_true', help='æª¢æŸ¥ç¶²è·¯é€£æ¥')
    
    args = parser.parse_args()
    
    if args.check:
        check_system_health()
    elif args.clear_cache:
        clear_cache()
    elif args.backup:
        backup_cache()
    elif args.restore:
        restore_cache_backup(args.restore)
    elif args.network:
        check_network_connectivity()
    else:
        # å¦‚æœæ²’æœ‰åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©ä¿¡æ¯
        parser.print_help()
