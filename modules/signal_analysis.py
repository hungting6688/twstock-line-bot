import os
import json
import gspread
import requests
import pandas as pd
from base64 import b64decode
from datetime import datetime, timedelta
from google.oauth2.service_account import Credentials
from modules.finmind_utils import get_latest_valid_trading_date, fetch_finmind_data, get_hot_stock_ids

def get_sheet_tracking_stocks():
    try:
        sheet_key = os.getenv("GOOGLE_SHEET_ID")
        json_key = os.getenv("GOOGLE_JSON_KEY")
        if not (sheet_key and json_key):
            return []
        info = json.loads(b64decode(json_key))
        creds = Credentials.from_service_account_info(info, scopes=["https://www.googleapis.com/auth/spreadsheets"])
        gc = gspread.authorize(creds)
        sheet = gc.open_by_key(sheet_key).sheet1
        values = sheet.col_values(1)[1:]  # å¿½ç•¥ç¬¬ä¸€åˆ—æ¨™é¡Œ
        return [v.strip() for v in values if v.strip()]
    except Exception as e:
        print(f"âŒ Google Sheet è®€å–å¤±æ•—ï¼š{e}")
        return []

def fetch_institutional_data(stock_id):
    token = os.getenv("FINMIND_TOKEN")
    url = "https://api.finmindtrade.com/api/v4/data"
    date = get_latest_valid_trading_date()
    params = {
        "dataset": "TaiwanStockInstitutionalInvestorsBuySell",
        "data_id": stock_id,
        "start_date": (datetime.strptime(date, "%Y-%m-%d") - timedelta(days=10)).strftime("%Y-%m-%d"),
        "end_date": date,
        "token": token
    }
    resp = requests.get(url, params=params)
    data = resp.json().get("data", [])
    df = pd.DataFrame(data)
    return df

def check_institutional_buying(df):
    if df.empty or "buy" not in df.columns or "sell" not in df.columns:
        return False
    df["net_buy"] = df["buy"] - df["sell"]
    net = df.groupby("date")["net_buy"].sum()
    return (net.tail(3) > 0).sum() >= 3  # è¿‘ä¸‰æ—¥ä¸­è²·è¶…é”ä¸‰å¤©ä»¥ä¸Š

def fetch_eps_growth(stock_id):
    token = os.getenv("FINMIND_TOKEN")
    url = "https://api.finmindtrade.com/api/v4/data"
    params = {
        "dataset": "TaiwanStockFinancialStatements",
        "data_id": stock_id,
        "token": token
    }
    resp = requests.get(url, params=params)
    data = resp.json().get("data", [])
    df = pd.DataFrame(data)
    if df.empty or "EPS" not in df.columns:
        return False
    df = df[df["statement_type"] == "Q4"]  # å–æ¯å¹´ EPS
    df["EPS"] = pd.to_numeric(df["EPS"], errors="coerce")
    df = df.sort_values("date")
    if len(df) < 2:
        return False
    latest, previous = df.iloc[-1]["EPS"], df.iloc[-2]["EPS"]
    return latest > previous and latest > 1  # å¹´å¢ä¸” EPS > 1

def analyze_stocks_with_signals(title="ğŸ“Š æ¨è–¦è‚¡å ±å‘Š", limit=100):
    hot_ids = get_hot_stock_ids(limit=limit)
    extra_ids = get_sheet_tracking_stocks()
    stock_ids = list(set(hot_ids + extra_ids))
    date = get_latest_valid_trading_date()
    results = []

    for sid in stock_ids:
        try:
            df = fetch_finmind_data(stock_id=sid, start_date="2024-01-01", end_date=date)
            if df is None or df.empty or "close" not in df.columns:
                print(f"âš ï¸ FinMind ç„¡è³‡æ–™ï¼š{sid}")
                continue

            latest = df.iloc[-1]
            close = latest["close"]
            signals = []
            score = 0

            # æŠ€è¡“æŒ‡æ¨™
            rsi = latest.get("rsi_6", 50)
            k = latest.get("kdj_k_9_3", 50)
            d = latest.get("kdj_d_9_3", 50)
            ma5 = latest.get("ma_5", close)
            ma20 = latest.get("ma_20", close)
            dif = latest.get("macd_dif_12_26_9", 0)
            macd = latest.get("macd_macd_12_26_9", 0)
            upper = latest.get("bolling_upper", close)
            lower = latest.get("bolling_lower", close)
            high = latest.get("high", close)
            low = latest.get("low", close)

            if rsi < 30:
                signals.append("ğŸŸ¢ RSI < 30 è¶…è·Œå€ï¼Œç•™æ„åå½ˆï¼ˆåå½ˆæ½›åŠ›ï¼‰")
                score += 1
            elif rsi > 70:
                signals.append("ğŸ”º RSI > 70 éç†±ï¼Œç•™æ„æ‹‰å›ï¼ˆéç†±é è­¦ï¼‰")

            if k > d:
                signals.append("ğŸŸ¢ KD é»ƒé‡‘äº¤å‰ï¼ŒæŠ€è¡“è½‰å¼·ï¼ˆå¤šé ­è¨Šè™Ÿï¼‰")
                score += 1
            elif k < d:
                signals.append("ğŸ”» KD æ­»äº¡äº¤å‰ï¼Œå‹•èƒ½è½‰å¼±ï¼ˆç©ºé ­é¢¨éšªï¼‰")
            if k < 20:
                signals.append("ğŸ“‰ K å€¼è¶…è³£ï¼Œåå½ˆå¥‘æ©Ÿï¼ˆåå½ˆæ½›åŠ›ï¼‰")
                score += 1

            if ma5 > ma20:
                signals.append("ğŸŸ¢ çŸ­å‡ç©¿è¶Šé•·å‡ï¼Œè¶¨å‹¢ç¿»å¤šï¼ˆå¤šé ­è¨Šè™Ÿï¼‰")
                score += 1
            elif ma5 < ma20:
                signals.append("ğŸ”» å‡ç·šç©ºé ­æ’åˆ—ï¼Œè¶¨å‹¢è½‰å¼±ï¼ˆç©ºé ­é¢¨éšªï¼‰")

            if dif > macd and df["macd_dif_12_26_9"].iloc[-2] < df["macd_macd_12_26_9"].iloc[-2]:
                signals.append("ğŸŸ¢ MACD é»ƒé‡‘äº¤å‰ï¼Œå‹•èƒ½è½‰å¼·ï¼ˆå¤šé ­è¨Šè™Ÿï¼‰")
                score += 1
            elif dif < macd and df["macd_dif_12_26_9"].iloc[-2] > df["macd_macd_12_26_9"].iloc[-2]:
                signals.append("ğŸ”» MACD æ­»äº¡äº¤å‰ï¼Œè½‰å¼±è¨Šè™Ÿï¼ˆç©ºé ­é¢¨éšªï¼‰")

            if close <= lower * 1.02:
                signals.append("ğŸ“‰ æ¥è¿‘å¸ƒæ—ä¸‹ç·£ï¼Œä½æª”è§€å¯Ÿï¼ˆåå½ˆæ½›åŠ›ï¼‰")
                score += 1
            if close >= upper * 0.99:
                signals.append("ğŸ“ˆ çªç ´å¸ƒæ—ä¸Šè»Œï¼ŒçŸ­ç·šå¼·å‹¢ï¼ˆéç†±é è­¦ï¼‰")

            if close == high:
                signals.append("ğŸŸ¢ æ”¶ç›¤æ”¶æœ€é«˜ï¼Œå¤šæ–¹åŠ›é“å¼·ï¼ˆå¤šé ­è¨Šè™Ÿï¼‰")
                score += 1
            elif close == low:
                signals.append("ğŸ”» æ”¶ç›¤æ”¶æœ€ä½ï¼Œç©ºæ–¹åŠ›é“å¼·ï¼ˆç©ºé ­é¢¨éšªï¼‰")

            # æ³•äººè²·è¶…è¨Šè™Ÿ
            institutional_df = fetch_institutional_data(sid)
            if check_institutional_buying(institutional_df):
                signals.append("âœ… æ³•äººé€£ 3 è²·ï¼Œè³‡é‡‘åå¤šä½ˆå±€ï¼ˆä¸­ç·šåå¤šï¼‰")
                score += 1

            # EPS æˆé•·è¨Šè™Ÿ
            if fetch_eps_growth(sid):
                signals.append("ğŸŒŸ EPS å¹´å¢ï¼ŒåŸºæœ¬é¢è½‰å¼·ï¼ˆä¸­é•·ç·šæ½›åŠ›ï¼‰")
                score += 1

            if signals:
                results.append({
                    "stock_id": sid,
                    "score": score,
                    "signals": signals
                })

        except Exception as e:
            print(f"âŒ è™•ç† {sid} å¤±æ•—ï¼š{e}")

    if not results:
        return f"{title}\nä»Šæ—¥ç„¡ç¬¦åˆæ¢ä»¶çš„æ¨è–¦è‚¡ã€‚"

    sorted_results = sorted(results, key=lambda x: x["score"], reverse=True)
    lines = [f"{title}"]
    for item in sorted_results:
        lines.append(f"ã€{item['stock_id']}ã€‘\n" + "\n".join(item["signals"]) + f"\nâ­ï¸ è¨Šè™Ÿåˆ†æ•¸ï¼š{item['score']}\n")

    return "\n".join(lines)
